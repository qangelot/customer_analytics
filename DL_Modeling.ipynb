{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Business case\n",
    "\n",
    "We get data from an Audiobook app. Logically, it relates only to the audio versions of books. Each customer in the database has made a purchase at least once, that's why he/she is in the database. We want to create a machine learning algorithm based on our available data that can predict if a customer will buy again.\n",
    "\n",
    "The main idea is that if a customer has a low probability of coming back, there is no reason to spend any money on advertizing to him/her. If we can focus our efforts ONLY on customers that are likely to convert again, we can make great savings. Moreover, this model can identify the most important metrics for a customer to come back again.\n",
    "\n",
    "There are several variables: Customer ID, Book length in mins_avg (average of all purchases), Book length in minutes_sum (sum of all purchases), Price Paid_avg (average of all purchases), Price paid_sum (sum of all purchases), Review (a Boolean variable), Review (out of 10), Total minutes listened, Completion (from 0 to 1), Support requests (number), and Last visited minus purchase date (in days).\n",
    "\n",
    "The targets are a Boolean variable (so 0, or 1). We are taking a period of 2 years in our inputs, and the next 6 months as targets. So, in fact, we are predicting if: based on the last 2 years of activity and engagement, a customer will convert in the next 6 months. 6 months sounds like a reasonable time. If they don't convert after 6 months, chances are they've gone to a competitor or didn't like the Audiobook way of digesting information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the machine learning algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import the relevant libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# temporary variable data, where we will store each of the three Audiobooks datasets\n",
    "data = np.load('Audiobooks_data_train.npz')\n",
    "\n",
    "# we extract the inputs using the keyword under which we saved them\n",
    "train_inputs = data['inputs'].astype(np.float)\n",
    "# targets must be int because of sparse_categorical_crossentropy (to be able to smoothly one-hot encode them)\n",
    "train_targets = data['targets'].astype(np.int)\n",
    "\n",
    "#validation data\n",
    "data = np.load('Audiobooks_data_validation.npz')\n",
    "validation_inputs, validation_targets = data['inputs'].astype(np.float), data['targets'].astype(np.int)\n",
    "\n",
    "#test data\n",
    "data = np.load('Audiobooks_data_test.npz')\n",
    "test_inputs, test_targets = data['inputs'].astype(np.float), data['targets'].astype(np.int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model\n",
    "Outline, optimizers, loss, early stopping and training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "36/36 - 0s - loss: 0.5521 - accuracy: 0.7946 - val_loss: 0.3953 - val_accuracy: 0.8859\n",
      "Epoch 2/100\n",
      "36/36 - 0s - loss: 0.3764 - accuracy: 0.8715 - val_loss: 0.3008 - val_accuracy: 0.8993\n",
      "Epoch 3/100\n",
      "36/36 - 0s - loss: 0.3286 - accuracy: 0.8793 - val_loss: 0.2774 - val_accuracy: 0.9016\n",
      "Epoch 4/100\n",
      "36/36 - 0s - loss: 0.3039 - accuracy: 0.8863 - val_loss: 0.2647 - val_accuracy: 0.9016\n",
      "Epoch 5/100\n",
      "36/36 - 0s - loss: 0.2897 - accuracy: 0.8910 - val_loss: 0.2563 - val_accuracy: 0.9060\n",
      "Epoch 6/100\n",
      "36/36 - 0s - loss: 0.2785 - accuracy: 0.8966 - val_loss: 0.2527 - val_accuracy: 0.9105\n",
      "Epoch 7/100\n",
      "36/36 - 0s - loss: 0.2721 - accuracy: 0.8963 - val_loss: 0.2528 - val_accuracy: 0.9105\n",
      "Epoch 8/100\n",
      "36/36 - 0s - loss: 0.2638 - accuracy: 0.9000 - val_loss: 0.2458 - val_accuracy: 0.9060\n",
      "Epoch 9/100\n",
      "36/36 - 0s - loss: 0.2606 - accuracy: 0.9003 - val_loss: 0.2475 - val_accuracy: 0.9128\n",
      "Epoch 10/100\n",
      "36/36 - 0s - loss: 0.2550 - accuracy: 0.9028 - val_loss: 0.2437 - val_accuracy: 0.9128\n",
      "Epoch 11/100\n",
      "36/36 - 0s - loss: 0.2539 - accuracy: 0.9028 - val_loss: 0.2491 - val_accuracy: 0.9083\n",
      "Epoch 12/100\n",
      "36/36 - 0s - loss: 0.2527 - accuracy: 0.9050 - val_loss: 0.2427 - val_accuracy: 0.9105\n",
      "Epoch 13/100\n",
      "36/36 - 0s - loss: 0.2478 - accuracy: 0.9044 - val_loss: 0.2387 - val_accuracy: 0.9150\n",
      "Epoch 14/100\n",
      "36/36 - 0s - loss: 0.2451 - accuracy: 0.9072 - val_loss: 0.2405 - val_accuracy: 0.9105\n",
      "Epoch 15/100\n",
      "36/36 - 0s - loss: 0.2427 - accuracy: 0.9078 - val_loss: 0.2363 - val_accuracy: 0.9105\n",
      "Epoch 16/100\n",
      "36/36 - 0s - loss: 0.2407 - accuracy: 0.9081 - val_loss: 0.2394 - val_accuracy: 0.9105\n",
      "Epoch 17/100\n",
      "36/36 - 0s - loss: 0.2402 - accuracy: 0.9086 - val_loss: 0.2389 - val_accuracy: 0.9060\n",
      "Epoch 18/100\n",
      "36/36 - 0s - loss: 0.2396 - accuracy: 0.9081 - val_loss: 0.2366 - val_accuracy: 0.9128\n",
      "Epoch 19/100\n",
      "36/36 - 0s - loss: 0.2381 - accuracy: 0.9095 - val_loss: 0.2375 - val_accuracy: 0.9105\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f8a142087f0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# set the output size : it's a binary outcome\n",
    "output_size = 2\n",
    "# use same hidden layer size for both hidden layers (not necessary)\n",
    "hidden_layer_size = 50\n",
    "\n",
    "# define the structure of the model\n",
    "model = tf.keras.Sequential([\n",
    "    # tf.keras.layers.Dense is basically implementing: output = activation(dot(input, weight) + bias)\n",
    "    # most important arguments are hidden_layer_size and activation function\n",
    "    tf.keras.layers.Dense(hidden_layer_size, activation='relu'),\n",
    "    tf.keras.layers.Dense(hidden_layer_size, activation='relu'),\n",
    "    # the final layer is activated with softmax\n",
    "    tf.keras.layers.Dense(output_size, activation='softmax')\n",
    "])\n",
    "\n",
    "# we define the optimizer we'd like to use, the loss function,\n",
    "# and the metrics we are interested in obtaining at each iteration\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# set the batch size\n",
    "batch_size = 100\n",
    "# set a maximum number of training epochs\n",
    "max_epochs = 100\n",
    "\n",
    "# let's set patience=4, to be a bit tolerant against random validation loss increases\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(patience=4)\n",
    "\n",
    "# fit the model\n",
    "model.fit(train_inputs,\n",
    "          train_targets,\n",
    "          batch_size=batch_size,\n",
    "          # epochs that we will train for\n",
    "          epochs=max_epochs,\n",
    "          # callbacks are functions called by a task when a task is completed\n",
    "          # task here is to check if val_loss is increasing at least 4 times in a row\n",
    "          callbacks=[early_stopping],\n",
    "          validation_data=(validation_inputs, validation_targets),\n",
    "          verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the model\n",
    "\n",
    "After training on the training data and validating on the validation data, we test the final prediction power of our model by running it on the test dataset that the algorithm has NEVER seen before.\n",
    "\n",
    "It is very important to realize that fiddling with the hyperparameters overfits the validation dataset. \n",
    "The test is the absolute final instance. We should not test before you are completely done with adjusting our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 0s 994us/step - loss: 0.2365 - accuracy: 0.9085\n"
     ]
    }
   ],
   "source": [
    "# getting the loss (which is there by default) \n",
    "# and whatever was specified in the 'metrics' argument when fitting the model\n",
    "test_loss, test_accuracy = model.evaluate(test_inputs, test_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test loss: 0.24 \n",
      "Test accuracy: 90.85%\n"
     ]
    }
   ],
   "source": [
    "print('\\nTest loss: {0:.2f} \\nTest accuracy: {1:.2f}%'.format(test_loss, test_accuracy*100.))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obtain the probability for a customer to convert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.22, 0.78],\n",
       "       [0.07, 0.93],\n",
       "       [0.66, 0.34],\n",
       "       [0.15, 0.85],\n",
       "       [0.15, 0.85],\n",
       "       [0.  , 1.  ],\n",
       "       [1.  , 0.  ],\n",
       "       [0.9 , 0.1 ],\n",
       "       [0.49, 0.51],\n",
       "       [1.  , 0.  ],\n",
       "       [0.14, 0.86],\n",
       "       [0.  , 1.  ],\n",
       "       [0.14, 0.86],\n",
       "       [0.  , 1.  ],\n",
       "       [1.  , 0.  ],\n",
       "       [0.  , 1.  ],\n",
       "       [1.  , 0.  ],\n",
       "       [0.12, 0.88],\n",
       "       [1.  , 0.  ],\n",
       "       [1.  , 0.  ],\n",
       "       [1.  , 0.  ],\n",
       "       [0.  , 1.  ],\n",
       "       [0.15, 0.85],\n",
       "       [0.89, 0.11],\n",
       "       [0.07, 0.93],\n",
       "       [0.8 , 0.2 ],\n",
       "       [0.96, 0.04],\n",
       "       [0.07, 0.93],\n",
       "       [0.98, 0.02],\n",
       "       [0.  , 1.  ],\n",
       "       [0.17, 0.83],\n",
       "       [1.  , 0.  ],\n",
       "       [1.  , 0.  ],\n",
       "       [1.  , 0.  ],\n",
       "       [1.  , 0.  ],\n",
       "       [1.  , 0.  ],\n",
       "       [0.  , 1.  ],\n",
       "       [0.87, 0.13],\n",
       "       [0.79, 0.21],\n",
       "       [0.05, 0.95],\n",
       "       [0.  , 1.  ],\n",
       "       [0.6 , 0.4 ],\n",
       "       [0.  , 1.  ],\n",
       "       [0.99, 0.01],\n",
       "       [0.89, 0.11],\n",
       "       [1.  , 0.  ],\n",
       "       [0.12, 0.88],\n",
       "       [0.17, 0.83],\n",
       "       [0.88, 0.12],\n",
       "       [0.05, 0.95],\n",
       "       [0.13, 0.87],\n",
       "       [0.59, 0.41],\n",
       "       [0.94, 0.06],\n",
       "       [0.8 , 0.2 ],\n",
       "       [0.  , 1.  ],\n",
       "       [0.  , 1.  ],\n",
       "       [0.07, 0.93],\n",
       "       [0.18, 0.82],\n",
       "       [0.15, 0.85],\n",
       "       [0.98, 0.02],\n",
       "       [0.76, 0.24],\n",
       "       [0.91, 0.09],\n",
       "       [0.21, 0.79],\n",
       "       [0.78, 0.22],\n",
       "       [0.11, 0.89],\n",
       "       [1.  , 0.  ],\n",
       "       [0.92, 0.08],\n",
       "       [0.92, 0.08],\n",
       "       [0.75, 0.25],\n",
       "       [0.96, 0.04],\n",
       "       [0.  , 1.  ],\n",
       "       [0.92, 0.08],\n",
       "       [0.  , 1.  ],\n",
       "       [0.04, 0.96],\n",
       "       [0.15, 0.85],\n",
       "       [0.97, 0.03],\n",
       "       [0.08, 0.92],\n",
       "       [0.22, 0.78],\n",
       "       [0.11, 0.89],\n",
       "       [1.  , 0.  ],\n",
       "       [0.67, 0.33],\n",
       "       [0.18, 0.82],\n",
       "       [1.  , 0.  ],\n",
       "       [0.  , 1.  ],\n",
       "       [0.16, 0.84],\n",
       "       [0.  , 1.  ],\n",
       "       [0.16, 0.84],\n",
       "       [0.14, 0.86],\n",
       "       [0.  , 1.  ],\n",
       "       [0.93, 0.07],\n",
       "       [0.08, 0.92],\n",
       "       [0.96, 0.04],\n",
       "       [1.  , 0.  ],\n",
       "       [1.  , 0.  ],\n",
       "       [0.  , 1.  ],\n",
       "       [0.08, 0.92],\n",
       "       [0.04, 0.96],\n",
       "       [0.16, 0.84],\n",
       "       [1.  , 0.  ],\n",
       "       [0.99, 0.01],\n",
       "       [0.01, 0.99],\n",
       "       [0.73, 0.27],\n",
       "       [0.16, 0.84],\n",
       "       [0.15, 0.85],\n",
       "       [0.22, 0.78],\n",
       "       [1.  , 0.  ],\n",
       "       [0.17, 0.83],\n",
       "       [0.  , 1.  ],\n",
       "       [0.82, 0.18],\n",
       "       [0.99, 0.01],\n",
       "       [0.16, 0.84],\n",
       "       [0.88, 0.12],\n",
       "       [0.34, 0.66],\n",
       "       [0.79, 0.21],\n",
       "       [0.  , 1.  ],\n",
       "       [0.  , 1.  ],\n",
       "       [1.  , 0.  ],\n",
       "       [0.23, 0.77],\n",
       "       [0.12, 0.88],\n",
       "       [0.01, 0.99],\n",
       "       [1.  , 0.  ],\n",
       "       [0.22, 0.78],\n",
       "       [1.  , 0.  ],\n",
       "       [0.14, 0.86],\n",
       "       [0.11, 0.89],\n",
       "       [0.  , 1.  ],\n",
       "       [1.  , 0.  ],\n",
       "       [0.83, 0.17],\n",
       "       [0.15, 0.85],\n",
       "       [0.16, 0.84],\n",
       "       [0.93, 0.07],\n",
       "       [0.  , 1.  ],\n",
       "       [0.22, 0.78],\n",
       "       [0.  , 1.  ],\n",
       "       [0.82, 0.18],\n",
       "       [1.  , 0.  ],\n",
       "       [0.11, 0.89],\n",
       "       [0.87, 0.13],\n",
       "       [0.  , 1.  ],\n",
       "       [0.2 , 0.8 ],\n",
       "       [0.08, 0.92],\n",
       "       [0.09, 0.91],\n",
       "       [0.1 , 0.9 ],\n",
       "       [0.76, 0.24],\n",
       "       [0.67, 0.33],\n",
       "       [0.15, 0.85],\n",
       "       [0.21, 0.79],\n",
       "       [0.1 , 0.9 ],\n",
       "       [1.  , 0.  ],\n",
       "       [0.77, 0.23],\n",
       "       [0.24, 0.76],\n",
       "       [0.  , 1.  ],\n",
       "       [0.  , 1.  ],\n",
       "       [0.96, 0.04],\n",
       "       [1.  , 0.  ],\n",
       "       [1.  , 0.  ],\n",
       "       [0.45, 0.55],\n",
       "       [0.97, 0.03],\n",
       "       [0.84, 0.16],\n",
       "       [0.15, 0.85],\n",
       "       [0.15, 0.85],\n",
       "       [0.18, 0.82],\n",
       "       [0.01, 0.99],\n",
       "       [0.  , 1.  ],\n",
       "       [0.12, 0.88],\n",
       "       [0.77, 0.23],\n",
       "       [0.14, 0.86],\n",
       "       [0.94, 0.06],\n",
       "       [0.96, 0.04],\n",
       "       [0.6 , 0.4 ],\n",
       "       [0.15, 0.85],\n",
       "       [0.17, 0.83],\n",
       "       [0.96, 0.04],\n",
       "       [0.96, 0.04],\n",
       "       [0.98, 0.02],\n",
       "       [0.  , 1.  ],\n",
       "       [0.22, 0.78],\n",
       "       [0.17, 0.83],\n",
       "       [0.  , 1.  ],\n",
       "       [0.16, 0.84],\n",
       "       [0.83, 0.17],\n",
       "       [0.35, 0.65],\n",
       "       [0.85, 0.15],\n",
       "       [0.87, 0.13],\n",
       "       [0.  , 1.  ],\n",
       "       [0.88, 0.12],\n",
       "       [0.  , 1.  ],\n",
       "       [0.  , 1.  ],\n",
       "       [0.16, 0.84],\n",
       "       [0.15, 0.85],\n",
       "       [0.95, 0.05],\n",
       "       [0.09, 0.91],\n",
       "       [0.01, 0.99],\n",
       "       [1.  , 0.  ],\n",
       "       [0.  , 1.  ],\n",
       "       [0.83, 0.17],\n",
       "       [0.92, 0.08],\n",
       "       [0.79, 0.21],\n",
       "       [0.14, 0.86],\n",
       "       [0.  , 1.  ],\n",
       "       [0.88, 0.12],\n",
       "       [0.91, 0.09],\n",
       "       [0.17, 0.83],\n",
       "       [0.08, 0.92],\n",
       "       [0.11, 0.89],\n",
       "       [0.13, 0.87],\n",
       "       [1.  , 0.  ],\n",
       "       [0.77, 0.23],\n",
       "       [0.  , 1.  ],\n",
       "       [0.14, 0.86],\n",
       "       [0.12, 0.88],\n",
       "       [1.  , 0.  ],\n",
       "       [1.  , 0.  ],\n",
       "       [0.02, 0.98],\n",
       "       [0.  , 1.  ],\n",
       "       [0.08, 0.92],\n",
       "       [0.91, 0.09],\n",
       "       [0.  , 1.  ],\n",
       "       [0.96, 0.04],\n",
       "       [0.92, 0.08],\n",
       "       [0.  , 1.  ],\n",
       "       [1.  , 0.  ],\n",
       "       [0.83, 0.17],\n",
       "       [0.  , 1.  ],\n",
       "       [1.  , 0.  ],\n",
       "       [1.  , 0.  ],\n",
       "       [0.92, 0.08],\n",
       "       [0.88, 0.12],\n",
       "       [0.24, 0.76],\n",
       "       [0.16, 0.84],\n",
       "       [0.22, 0.78],\n",
       "       [1.  , 0.  ],\n",
       "       [0.01, 0.99],\n",
       "       [1.  , 0.  ],\n",
       "       [0.88, 0.12],\n",
       "       [1.  , 0.  ],\n",
       "       [0.25, 0.75],\n",
       "       [0.  , 1.  ],\n",
       "       [0.84, 0.16],\n",
       "       [0.  , 1.  ],\n",
       "       [0.04, 0.96],\n",
       "       [0.01, 0.99],\n",
       "       [0.93, 0.07],\n",
       "       [0.96, 0.04],\n",
       "       [0.01, 0.99],\n",
       "       [0.96, 0.04],\n",
       "       [0.  , 1.  ],\n",
       "       [0.91, 0.09],\n",
       "       [0.15, 0.85],\n",
       "       [0.99, 0.01],\n",
       "       [0.07, 0.93],\n",
       "       [0.  , 1.  ],\n",
       "       [0.58, 0.42],\n",
       "       [0.98, 0.02],\n",
       "       [0.91, 0.09],\n",
       "       [0.7 , 0.3 ],\n",
       "       [0.91, 0.09],\n",
       "       [0.92, 0.08],\n",
       "       [1.  , 0.  ],\n",
       "       [0.27, 0.73],\n",
       "       [0.16, 0.84],\n",
       "       [0.08, 0.92],\n",
       "       [1.  , 0.  ],\n",
       "       [0.11, 0.89],\n",
       "       [0.67, 0.33],\n",
       "       [0.  , 1.  ],\n",
       "       [1.  , 0.  ],\n",
       "       [0.23, 0.77],\n",
       "       [0.55, 0.45],\n",
       "       [0.12, 0.88],\n",
       "       [0.07, 0.93],\n",
       "       [0.12, 0.88],\n",
       "       [1.  , 0.  ],\n",
       "       [0.09, 0.91],\n",
       "       [0.  , 1.  ],\n",
       "       [0.09, 0.91],\n",
       "       [0.73, 0.27],\n",
       "       [1.  , 0.  ],\n",
       "       [0.  , 1.  ],\n",
       "       [0.  , 1.  ],\n",
       "       [0.21, 0.79],\n",
       "       [0.  , 1.  ],\n",
       "       [0.  , 1.  ],\n",
       "       [0.1 , 0.9 ],\n",
       "       [0.93, 0.07],\n",
       "       [0.93, 0.07],\n",
       "       [0.66, 0.34],\n",
       "       [0.98, 0.02],\n",
       "       [0.01, 0.99],\n",
       "       [0.  , 1.  ],\n",
       "       [0.  , 1.  ],\n",
       "       [0.22, 0.78],\n",
       "       [1.  , 0.  ],\n",
       "       [0.01, 0.99],\n",
       "       [0.  , 1.  ],\n",
       "       [0.  , 1.  ],\n",
       "       [0.  , 1.  ],\n",
       "       [0.  , 1.  ],\n",
       "       [0.45, 0.55],\n",
       "       [0.14, 0.86],\n",
       "       [0.53, 0.47],\n",
       "       [0.46, 0.54],\n",
       "       [1.  , 0.  ],\n",
       "       [1.  , 0.  ],\n",
       "       [0.03, 0.97],\n",
       "       [0.91, 0.09],\n",
       "       [1.  , 0.  ],\n",
       "       [0.89, 0.11],\n",
       "       [0.66, 0.34],\n",
       "       [1.  , 0.  ],\n",
       "       [0.  , 1.  ],\n",
       "       [0.01, 0.99],\n",
       "       [0.1 , 0.9 ],\n",
       "       [0.89, 0.11],\n",
       "       [0.06, 0.94],\n",
       "       [0.  , 1.  ],\n",
       "       [0.  , 1.  ],\n",
       "       [0.7 , 0.3 ],\n",
       "       [1.  , 0.  ],\n",
       "       [0.22, 0.78],\n",
       "       [0.  , 1.  ],\n",
       "       [0.02, 0.98],\n",
       "       [1.  , 0.  ],\n",
       "       [0.77, 0.23],\n",
       "       [0.21, 0.79],\n",
       "       [0.53, 0.47],\n",
       "       [0.85, 0.15],\n",
       "       [0.17, 0.83],\n",
       "       [0.  , 1.  ],\n",
       "       [0.75, 0.25],\n",
       "       [1.  , 0.  ],\n",
       "       [0.6 , 0.4 ],\n",
       "       [0.9 , 0.1 ],\n",
       "       [0.15, 0.85],\n",
       "       [0.81, 0.19],\n",
       "       [0.96, 0.04],\n",
       "       [1.  , 0.  ],\n",
       "       [0.91, 0.09],\n",
       "       [1.  , 0.  ],\n",
       "       [0.  , 1.  ],\n",
       "       [0.02, 0.98],\n",
       "       [0.11, 0.89],\n",
       "       [0.83, 0.17],\n",
       "       [0.08, 0.92],\n",
       "       [0.16, 0.84],\n",
       "       [0.83, 0.17],\n",
       "       [0.34, 0.66],\n",
       "       [0.27, 0.73],\n",
       "       [0.76, 0.24],\n",
       "       [0.35, 0.65],\n",
       "       [0.1 , 0.9 ],\n",
       "       [0.95, 0.05],\n",
       "       [0.97, 0.03],\n",
       "       [0.07, 0.93],\n",
       "       [0.91, 0.09],\n",
       "       [1.  , 0.  ],\n",
       "       [0.02, 0.98],\n",
       "       [0.13, 0.87],\n",
       "       [0.8 , 0.2 ],\n",
       "       [0.76, 0.24],\n",
       "       [0.66, 0.34],\n",
       "       [0.08, 0.92],\n",
       "       [1.  , 0.  ],\n",
       "       [0.22, 0.78],\n",
       "       [0.88, 0.12],\n",
       "       [0.88, 0.12],\n",
       "       [0.92, 0.08],\n",
       "       [0.08, 0.92],\n",
       "       [0.  , 1.  ],\n",
       "       [0.9 , 0.1 ],\n",
       "       [0.  , 1.  ],\n",
       "       [0.  , 1.  ],\n",
       "       [1.  , 0.  ],\n",
       "       [0.04, 0.96],\n",
       "       [0.91, 0.09],\n",
       "       [0.92, 0.08],\n",
       "       [0.91, 0.09],\n",
       "       [0.97, 0.03],\n",
       "       [0.63, 0.37],\n",
       "       [0.96, 0.04],\n",
       "       [0.13, 0.87],\n",
       "       [0.88, 0.12],\n",
       "       [0.63, 0.37],\n",
       "       [0.  , 1.  ],\n",
       "       [0.93, 0.07],\n",
       "       [0.  , 1.  ],\n",
       "       [0.17, 0.83],\n",
       "       [0.24, 0.76],\n",
       "       [0.02, 0.98],\n",
       "       [0.85, 0.15],\n",
       "       [0.  , 1.  ],\n",
       "       [0.1 , 0.9 ],\n",
       "       [0.16, 0.84],\n",
       "       [1.  , 0.  ],\n",
       "       [0.72, 0.28],\n",
       "       [1.  , 0.  ],\n",
       "       [0.13, 0.87],\n",
       "       [0.87, 0.13],\n",
       "       [0.16, 0.84],\n",
       "       [0.51, 0.49],\n",
       "       [0.02, 0.98],\n",
       "       [0.07, 0.93],\n",
       "       [0.96, 0.04],\n",
       "       [0.69, 0.31],\n",
       "       [0.27, 0.73],\n",
       "       [1.  , 0.  ],\n",
       "       [0.22, 0.78],\n",
       "       [1.  , 0.  ],\n",
       "       [0.15, 0.85],\n",
       "       [0.08, 0.92],\n",
       "       [0.05, 0.95],\n",
       "       [0.92, 0.08],\n",
       "       [0.88, 0.12],\n",
       "       [0.  , 1.  ],\n",
       "       [0.  , 1.  ],\n",
       "       [0.16, 0.84],\n",
       "       [0.  , 1.  ],\n",
       "       [0.8 , 0.2 ],\n",
       "       [0.  , 1.  ],\n",
       "       [0.63, 0.37],\n",
       "       [0.04, 0.96],\n",
       "       [0.94, 0.06],\n",
       "       [0.72, 0.28],\n",
       "       [0.16, 0.84],\n",
       "       [1.  , 0.  ],\n",
       "       [0.18, 0.82],\n",
       "       [0.95, 0.05],\n",
       "       [1.  , 0.  ],\n",
       "       [1.  , 0.  ],\n",
       "       [0.63, 0.37],\n",
       "       [0.12, 0.88],\n",
       "       [0.11, 0.89],\n",
       "       [0.93, 0.07],\n",
       "       [1.  , 0.  ],\n",
       "       [0.84, 0.16],\n",
       "       [0.96, 0.04],\n",
       "       [1.  , 0.  ],\n",
       "       [1.  , 0.  ],\n",
       "       [0.66, 0.34],\n",
       "       [0.28, 0.72],\n",
       "       [0.  , 1.  ],\n",
       "       [0.  , 1.  ],\n",
       "       [1.  , 0.  ],\n",
       "       [0.98, 0.02],\n",
       "       [0.04, 0.96],\n",
       "       [1.  , 0.  ],\n",
       "       [0.14, 0.86],\n",
       "       [0.14, 0.86]], dtype=float32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# predicting the probability of each class using the 'predict' method\n",
    "model.predict(test_inputs).round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.78, 0.93, 0.34, 0.85, 0.85, 1.  , 0.  , 0.1 , 0.51, 0.  , 0.86,\n",
       "       1.  , 0.86, 1.  , 0.  , 1.  , 0.  , 0.88, 0.  , 0.  , 0.  , 1.  ,\n",
       "       0.85, 0.11, 0.93, 0.2 , 0.04, 0.93, 0.02, 1.  , 0.83, 0.  , 0.  ,\n",
       "       0.  , 0.  , 0.  , 1.  , 0.13, 0.21, 0.95, 1.  , 0.4 , 1.  , 0.01,\n",
       "       0.11, 0.  , 0.88, 0.83, 0.12, 0.95, 0.87, 0.41, 0.06, 0.2 , 1.  ,\n",
       "       1.  , 0.93, 0.82, 0.85, 0.02, 0.24, 0.09, 0.79, 0.22, 0.89, 0.  ,\n",
       "       0.08, 0.08, 0.25, 0.04, 1.  , 0.08, 1.  , 0.96, 0.85, 0.03, 0.92,\n",
       "       0.78, 0.89, 0.  , 0.33, 0.82, 0.  , 1.  , 0.84, 1.  , 0.84, 0.86,\n",
       "       1.  , 0.07, 0.92, 0.04, 0.  , 0.  , 1.  , 0.92, 0.96, 0.84, 0.  ,\n",
       "       0.01, 0.99, 0.27, 0.84, 0.85, 0.78, 0.  , 0.83, 1.  , 0.18, 0.01,\n",
       "       0.84, 0.12, 0.66, 0.21, 1.  , 1.  , 0.  , 0.77, 0.88, 0.99, 0.  ,\n",
       "       0.78, 0.  , 0.86, 0.89, 1.  , 0.  , 0.17, 0.85, 0.84, 0.07, 1.  ,\n",
       "       0.78, 1.  , 0.18, 0.  , 0.89, 0.13, 1.  , 0.8 , 0.92, 0.91, 0.9 ,\n",
       "       0.24, 0.33, 0.85, 0.79, 0.9 , 0.  , 0.23, 0.76, 1.  , 1.  , 0.04,\n",
       "       0.  , 0.  , 0.55, 0.03, 0.16, 0.85, 0.85, 0.82, 0.99, 1.  , 0.88,\n",
       "       0.23, 0.86, 0.06, 0.04, 0.4 , 0.85, 0.83, 0.04, 0.04, 0.02, 1.  ,\n",
       "       0.78, 0.83, 1.  , 0.84, 0.17, 0.65, 0.15, 0.13, 1.  , 0.12, 1.  ,\n",
       "       1.  , 0.84, 0.85, 0.05, 0.91, 0.99, 0.  , 1.  , 0.17, 0.08, 0.21,\n",
       "       0.86, 1.  , 0.12, 0.09, 0.83, 0.92, 0.89, 0.87, 0.  , 0.23, 1.  ,\n",
       "       0.86, 0.88, 0.  , 0.  , 0.98, 1.  , 0.92, 0.09, 1.  , 0.04, 0.08,\n",
       "       1.  , 0.  , 0.17, 1.  , 0.  , 0.  , 0.08, 0.12, 0.76, 0.84, 0.78,\n",
       "       0.  , 0.99, 0.  , 0.12, 0.  , 0.75, 1.  , 0.16, 1.  , 0.96, 0.99,\n",
       "       0.07, 0.04, 0.99, 0.04, 1.  , 0.09, 0.85, 0.01, 0.93, 1.  , 0.42,\n",
       "       0.02, 0.09, 0.3 , 0.09, 0.08, 0.  , 0.73, 0.84, 0.92, 0.  , 0.89,\n",
       "       0.33, 1.  , 0.  , 0.77, 0.45, 0.88, 0.93, 0.88, 0.  , 0.91, 1.  ,\n",
       "       0.91, 0.27, 0.  , 1.  , 1.  , 0.79, 1.  , 1.  , 0.9 , 0.07, 0.07,\n",
       "       0.34, 0.02, 0.99, 1.  , 1.  , 0.78, 0.  , 0.99, 1.  , 1.  , 1.  ,\n",
       "       1.  , 0.55, 0.86, 0.47, 0.54, 0.  , 0.  , 0.97, 0.09, 0.  , 0.11,\n",
       "       0.34, 0.  , 1.  , 0.99, 0.9 , 0.11, 0.94, 1.  , 1.  , 0.3 , 0.  ,\n",
       "       0.78, 1.  , 0.98, 0.  , 0.23, 0.79, 0.47, 0.15, 0.83, 1.  , 0.25,\n",
       "       0.  , 0.4 , 0.1 , 0.85, 0.19, 0.04, 0.  , 0.09, 0.  , 1.  , 0.98,\n",
       "       0.89, 0.17, 0.92, 0.84, 0.17, 0.66, 0.73, 0.24, 0.65, 0.9 , 0.05,\n",
       "       0.03, 0.93, 0.09, 0.  , 0.98, 0.87, 0.2 , 0.24, 0.34, 0.92, 0.  ,\n",
       "       0.78, 0.12, 0.12, 0.08, 0.92, 1.  , 0.1 , 1.  , 1.  , 0.  , 0.96,\n",
       "       0.09, 0.08, 0.09, 0.03, 0.37, 0.04, 0.87, 0.12, 0.37, 1.  , 0.07,\n",
       "       1.  , 0.83, 0.76, 0.98, 0.15, 1.  , 0.9 , 0.84, 0.  , 0.28, 0.  ,\n",
       "       0.87, 0.13, 0.84, 0.49, 0.98, 0.93, 0.04, 0.31, 0.73, 0.  , 0.78,\n",
       "       0.  , 0.85, 0.92, 0.95, 0.08, 0.12, 1.  , 1.  , 0.84, 1.  , 0.2 ,\n",
       "       1.  , 0.37, 0.96, 0.06, 0.28, 0.84, 0.  , 0.82, 0.05, 0.  , 0.  ,\n",
       "       0.37, 0.88, 0.89, 0.07, 0.  , 0.16, 0.04, 0.  , 0.  , 0.34, 0.72,\n",
       "       1.  , 1.  , 0.  , 0.02, 0.96, 0.  , 0.86, 0.86], dtype=float32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Alternatively, we can get only the second column\n",
    "# The main idea is that we are often interested in ONLY ONE of the two outcomes\n",
    "# In this case we would like to know if the customer will convert again\n",
    "# Once more, we can round to 0 digits, to achieve only 0s or 1s\n",
    "model.predict(test_inputs)[:,1].round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1,\n",
       "       1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0,\n",
       "       0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0,\n",
       "       0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1,\n",
       "       1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0,\n",
       "       1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1,\n",
       "       1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0,\n",
       "       0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1,\n",
       "       1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0,\n",
       "       1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0,\n",
       "       1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1,\n",
       "       0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1,\n",
       "       0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0,\n",
       "       0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0,\n",
       "       0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0,\n",
       "       0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0,\n",
       "       0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1,\n",
       "       0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0,\n",
       "       1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0,\n",
       "       1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "       1, 1, 0, 0, 1, 0, 1, 1])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# a much better approach here would be to use argmax (arguments of the maxima)\n",
    "# which indicates the position of the highest argument row-wise or column-wise\n",
    "# here, we want ot know which column has the highest probability, therefore we set axis=1 \n",
    "# it's not mandatory here but it's great for multiclass classification problems\n",
    "np.argmax(model.predict(test_inputs),axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we save the model using the built-in method TensorFlow method\n",
    "# the HDF format is optimal for large numerical objects\n",
    "# the proper extension is .h5 to indicate HDF, version 5\n",
    "model.save('audiobooks_model.h5') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
